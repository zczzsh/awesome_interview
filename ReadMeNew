- 自我介绍
    
- 项目介绍

- 语言基础
    - C/C++
        - static  
        两个作用：限定作用域；保持变量静态化持久化；  
        静态变量位于静态存储区，全局静态变量在定义后在当前文件中可用；局部静态变量则在局部作用域内可用（如在函数内部，则函数结束后不可访问，下次再运行函数时可访问且内容不变）；
		静态变量都默认初始化为0；类中的静态标量属于类的所有实例共有，且不需要实例化即可访问。  
        静态函数也直在当前文件中可见；类中的静态函数则不需要实例化即可调用，但只可访问类内的静态成员或函数。  

		static全局变量，存储和其它全局变量没区别，都是在.data(已初始化)或者.bss(未初始化)内，但它只在定义它的源文件内有效，其他源文件无法访问它。
		全局变量、文件域的静态变量和类的静态成员变量在main执行之前的静态初始化过程中分配内存并初始化。
		普通局部变量在栈上分配，也可在堆上面分配（堆上分配用完需要释放）。
		静态局部变量，存储位置在.data中，如果用户没有初始化，则编译器自动初始化为0，所以在.data中，在程序的整个生命周期中存在。它只能被其作用域内的变量或者函数访问。


        - inline  
        内联函数，修饰简单的函数，可以在调用的时候直接替换成函数内容；  
        限制：函数本身不能复杂，不能包含if for等结构控制语句，同时也不能是递归函数  
        即使使用了inline也不一定有用，这得看编译器的意思，编译器认为函数比较复杂，则不会进行内联展开；即*inline只是一个建议*  
		为什么C++不支持内联成员函数为虚函数？ 其实很简单，内联函数就是为了在代码中直接展开，减少函数调用花费的代价，虚函数是为了在继承后对象能够准确的执行自己的动作，这是不可能统一的。
		虚函数机制：在每一个有虚函数的类里都有一个表VTABLE，存放虚函数地址
        内联函数：编译器把内联函数的代码存放在符号表中，每次调用会把函数代码插入到调用处，所以无法取得地址

        - extern  
        两种作用：表示变量或函数的定义在其他的文件中；用于进行链接指定；  
        第一、extern "C" fun(int a)表示函数fun在编译时函数名翻译按照C的规则来翻译，而避免C++编译器将函数换名，但这种方式会导致函数重载失效；  
        第二、extern后直接跟变量或函数时，表明该变量或函数的定义可能位于别的文件中，需要编译器在编译阶段查找其他文件（即该变量在别的地方有过定义，这个地方的变量应使用那个地方的变量来替换）。  


        - volatile  
        volatile 关键字是一种类型修饰符，用它声明的类型变量表示可以被某些编译器未知的因素更改，比如：操作系统、硬件或者其它线程等。
		遇到这个关键字声明的变量，编译器对访问该变量的代码就不再进行优化，从而可以提供对特殊地址的稳定访问。
		声明时语法：int volatile vInt; 当要求使用 volatile 声明的变量的值的时候，系统总是重新从它所在的内存读取数据，即使它前面的指令刚刚从该处读取过数据。而且读取的数据立刻被保存。
		
		   
        - public 公开 protected 子类、自己、友元类 private 自己、友元类

		- C++面向对象思想：
		- 封装 ：简单的把函数或者变量放在结果之中即class，并赋予一定的权限。

		- 继承： 对象是类的一个实例（例如手机类对应iphone），派生类继承了基类的全部数据和函数，并具有自己私有的数据和函数，是“is a”的关系。
		比如人是一个基类，那么男人就是他的派生类，男人也是人。
		C++中定义一个不能被继承的类，即子类继承之后不能正常实例化，此时如果将父类的构造函数设为private可以。进一步的话将析构函数设为private也可以。
		但是这样类本身也不能正常使用了，此时可以声明一个父类的友元类A，虚继承父类，则子类继承A时都需要自己实例化。实例化时需要调用A的构造函数。
		（虚继承：多个派生类保存相同基类的同名成员时，虽可以在不同的数据成员中分别存放不同的数据 ，但我们只需要相同的一份。）
		由于A是虚继承父类的，所以A本身可以调用父类的private的构造函数，A的子类不能调用，即达到目的。

		重载：是指同一可访问区内被声明的几个具有不同参数列（参数的类型，个数，顺序不同）的同名函数，根据参数列表确定调用哪个函数，重载不关心函数返回类型。
		隐藏：是指派生类的函数屏蔽了与其同名的基类函数，注意只要同名函数，不管参数列表是否相同，基类函数都会被隐藏。
		重写(覆盖)：是指派生类中存在重新定义的函数。其函数名，参数列表，返回值类型，所有都必须同基类中被重写的函数一致。只有函数体不同（花括号内），
		派生类调用时会调用派生类的重写函数，不会调用被重写函数。重写的基类中被重写的函数必须有virtual修饰。

        - 多态（使用virtual函数）  
		在基类定义一个接口函数，派生类分别继承并覆盖了这一接口函数。在运行时，动态的确定该用哪一个派生类的函数。这样的函数称为虚函数。
		一旦一个类里的某个函数被声明成了虚函数，那么其派生类的对应函数也会成为虚函数。
		纯虚函数：C++中包含纯虚函数的类，被称为是“抽象类”。抽象类不能使用new出对象，只有实现了这个纯虚函数的子类才能new出对象。
		不要为该函数编址，阻止类的实例化。
		C++中的纯虚函数更像是“只提供申明，没有实现”，是对子类的约束，是“接口继承”。 C++中的纯虚函数也是一种“运行时多态”。 
		纯虚函数在基类中类似于virtual void out1(string s)=0,可以有函数体; 实现必须在其派生类中去实现。
		构造函数不能声明为虚函数，析构函数可以：https://zhidao.baidu.com/question/559819164821940204.html

        接口的多种不同实现方式即为多态；父类中以virtual修饰的函数，在子类中存在同名同参的函数时，调用父类指针指向的子类实例，则调用的函数是子类的。  
        如A为父类，A中fun()为虚函数，B继承A，B中也有一个fun()，那么A* a = new B()时，a->fun()调用的是子类B中的函数。  
        原理：编译器在编译期间会为含有虚函数的类生成一张虚函数表，表中存有各个虚函数的函数指针；这张虚函数表为这个类的所有实例所共有，且位于进程的静态数据段。
		而继承了父类的子类中也会包含有父类的虚函数表，且与父类中虚函数相同的函数会将虚函数表中的相应指针位置覆盖，因而就会出现调用子类的函数的现象。 

		常见的不能声明为虚函数的有：普通函数（非成员函数）、静态成员函数、内联成员函数、构造函数、友元函数。
		 

        - 虚基类  
            如果某个子孙类通过各种方式继承下来（有多条继承的路径）发现最后多次继承了某个基类，那么就会发现这个基类会被多次实例化，用虚基类就可以解决这个问题。  
            虚基类的构造函数由最远的子类来确定    

        - const  和 宏定义（define）
        根据const右边的东西来确定是什么不变。  
        const int* a表示a指向的地址的内容不可变；int* const a表示a的内容不变（a存储的是地址，故地址不变，但地址指向的地方的内容可以变）；  
        const修饰函数时，当const在函数名前面时表示函数返回的内容不可修改（如函数访问public的变量，但是又不想让别人修改这个变量，可以将函数修饰为const函数）；
		当const在函数名后面（如fun() const这种）则表示该函数体内的所有操作均不可修改类的成员变量，也不可调用非const的函数（只可调用有const在后的）。
        宏定义：在编译阶段会直接被替换
		两者区别：（1）define是在编译的预处理阶段起作用，而const是在编译，运行时起作用
		          （2）define只是简单的替换，没有类型检查。而const有对应的数据类型
				  （3）define预处理后占用代码段空间，但是const实际上还是个变量，占用数据段空间
				  （4）const可以进行调试，define不能
				  （5）const不能被重定义，而define可以通过#undef取消某个符号的定义再重新定义
				  （6）#define使代码简单，而const不行

		- memcopy和memmove
		两者都是c中的库函数（string.h），作用都是拷贝一定长度的内容，参数都是void *dst, const void *src, size_t count;
		唯一的区别是，当内存发生局部重叠时，memmove保证拷贝的结果是正确的，而memcopy不能保证
		https://blog.csdn.net/li_ning_/article/details/51418400

		- strcpy和strncpy区别，哪个更安全
		strcpy：字串复制
　　    原型：char *strcpy(char *dest, char *src);
　　    功能：把src所指由'\0'结束的字符串复制到dest所指的数组中。
　　    说明：src和dest所指内存区域不可以重叠且dest必须有足够的空间来容纳src的字符串。返回指向dest的指针。
        注意：当src串长度>dest串长度时，程序仍会将整个src串复制到dest区域，可是dest数组已发生溢出。
　　    因此会导致dest栈空间溢出以致产生崩溃异常。如果不考虑src串的完整性，可以把dest数组最后一元素置为NULL，从dest串长度处插入NULL截取字串。
        strncpy   
	    原型：char * strncpy(char *dest, char *src, size_t n);
　　    功能：将字符串src中最多n个字符复制到字符数组dest中(它并不像strcpy一样遇到NULL才停止复制，而是等凑够n个字符才开始复制），返回指向dest的指针。
　　    说明：
　　    如果n > dest串长度，dest栈空间溢出产生崩溃异常。
　　    否则：
　　    1）src串长度<=dest串长度,(这里的串长度包含串尾NULL字符)
　　    如果n=(0, src串长度)，src的前n个字符复制到dest中。但是由于没有NULL字符，所以直接访问dest串会发生栈溢出的异常情况。
　　    如果n = src串长度，与strcpy一致。
　　    如果n = dest串长度，[0,src串长度]处存放于desk字串，(src串长度, dest串长度]处存放NULL。
　　    2）src串长度>dest串长度
　　    如果n =dest串长度，则dest串没有NULL字符，会导致输出会有乱码。如果不考虑src串复制完整性，可以将dest最后一字符置为NULL。
　　    综上，一般情况下，使用strncpy时，建议将n置为dest串长度（除非你将多个src串都复制到dest数组，并且从dest尾部反向操作)，复制完毕后，为保险起见，将dest串最后一字符置NULL，
        避免发生在第2)种情况下的输出乱码问题。当然喽，无论是strcpy还是strncpy，保证src串长度<dest串长度才是最重要的。

		- 模板类
		Template<typename T1，typename T2>（T1,T2算通用类型）
		模板类是类模板实例化后的一个产物。说个形象点的样例吧。
        我把类模板比作一个做饼干同的模子，而模板类就是用这个模子做出来的饼干，至于这个饼干是什么味道的就要看你自己在实例化时用的是什么材料了，你能够做巧克力饼干，
		也能够做豆沙饼干，这些饼干的除了材料不一样外，其它的东西都是一样的了。 

        - STL  
            - vector（如何扩容）  
            动态分配，在堆中分配内存；元素连续存放，且保留大小（数组大小减少也不会释放内存，因此vector占用的内存只增加不减少，只有在析构的时候才会被系统收回）；  
            扩容：当占有的内存不够时，会向系统申请当前大小的双倍内存，再调用拷贝构造函数将已有的数据复制过去。  
            之所以扩容是双倍，是为了方便内存收缩后，前面如果是以2的内存来进行分配的话到一定程度后就可以将前面分配过但已经不用的内存重新利用起来。  
            https://blog.csdn.net/dengheCSDN/article/details/78985684
            - map——红黑树  （红黑树具体情况见下数据结构）
            内部元素按照key自动排序（因此对于key为自定义类的情况需要重载操作符<）  
            map内部自建一颗红黑树(一种非严格意义上的平衡二叉树)，这颗树具有对数据自动排序的功能，所以在map内部所有的数据都是有序的。因此按照中序遍历会产生有序序列。
			在O(log n)时间内做查找，插入和删除。  
            - unordered_map  （实现原理是哈希表）
			在 unordered_map 内部，元素不会按任何顺序排序，而是通过主键的 hash 值将元素分组放置到 各个槽（Bucket，也可译成“桶”）中，
			这样就能通过主键快速地访问各个对应的元素。查找时间复杂度为O（1）
            - set  实现原理也是红黑树 在O(log n)时间内做查找，插入和删除。

        - 继承中的构造函数、析构函数调用顺序  
        构造函数调用顺序：先父后子；析构函数调用顺序：先子后父  

        - 函数参数入栈方式  
        从右往左，为了保证可变长度的变量顺利入栈  

        - 各种类型的变量内存分配方式  
        分为五个部分：  （C中没有自由存储区）
            - 栈：存储局部变量、函数参数等编译器才知道什么时候需要分配内存的变量
            - 堆：程序员自己控制分配，也由程序员自己回收（容易导致运行中的内存泄漏，但程序结束操作系统会自动收回）；存储的都是由malloc分配的内存。  
            - 自由存储区：用new等分配的内存块，和堆相似，但由delete销毁。 
            - 静态存储区：全局变量和静态变量；  （数据段和代码段）
            - 常量存储区：存储常量，不允许修改。  
            //- 程序代码区：存放程序、函数体的二进制代码。（这个没有）

        - 友元  
            在C++之中，类的友元函数是定义在类外部，但它有权访问类的所有私有（private）成员和保护（protected）成员。
			尽管友元函数的原型有在类的定义中出现过，但是友元函数并不是成员函数。
			友元可以是一个函数，该函数被称为友元函数；友元也可以是一个类，该类被称为友元类。  

		- 迷途指针，空指针
		失控指针：指的是不指向任何合法的对象的指针，可以指向任何地址，并且对该地址的数值进行修改或删除，可能会造成意想不到的后果。
		迷途指针：当所指向的对象被释放或者收回，但是对该指针没有作任何的修改，以至于该指针仍旧指向已经回收的内存地址，此情况下该指针称为迷途指针。
		野指针：未被初始化的指针，野指针所导致的错误和迷途指针非常相似，但野指针的问题更容易被发现。
		空指针常量：一个表示0值的整数常量，NULL作为一个宏定义为一个空指针常量。
		空指针：就是一个被赋值为0的指针，如果一个 空指针常量 赋给了一个有类型的指针变量，那么这个指针就叫空指针。
		重踏指针：被释放后的指针不置为空指针，不再指向任何合法的内存，它仍可能指向原来的内存块，此时再定义一个新的指针，两个指针都指向同一块内存。

		- C++11/14
		C++11包括大量的新特性：主要特征像lambda表达式和移动语义，实用的类型推导关键字auto，更简单的容器遍历方法，和大量使模板更容易使用的改进。
		https://blog.csdn.net/zdy0_2004/article/details/69934828
		C++ 14 https://baike.baidu.com/item/c++14/12424852

		- 指针和引用
		指针：指针是一个变量，只不过这个变量存储的是一个地址，指向内存的一个存储单元；而引用跟原来的变量实质上是同一个东西，只不过是原变量的一个别名而已。
		(2)引用不可以为空，当被创建的时候，必须初始化，而指针可以是空值，可以在任何时候被初始化。
        (3)可以有const指针，但是没有const引用；
        (4)指针可以有多级，但是引用只能是一级（int **p；合法 而 int &&a是不合法的）
        (5)指针的值可以为空，但是引用的值不能为NULL，并且引用在定义的时候必须初始化；
        (6)指针的值在初始化后可以改变，即指向其它的存储单元，而引用在进行初始化后就不会再改变了。
        (7)”sizeof引用”得到的是所指向的变量(对象)的大小，而”sizeof指针”得到的是指针本身的大小；
        (8)指针和引用的自增(++)运算意义不一样；
        (9)如果返回动态内存分配的对象或者内存，必须使用指针，引用可能引起内存泄漏；

		- new，delete，malloc，free
		1.new/delete是C++关键字，需要编译器支持。malloc/free是库函数，需要头文件支持c。
		2.使用new操作符申请内存分配时无须指定内存块的大小，编译器会根据类型信息自行计算（堆）。而malloc则需要显式地指出所需内存的尺寸（自由存储区）。

		3.new操作符内存分配成功时，返回的是对象类型的指针，类型严格与对象匹配，无须进行类型转换，故new是符合类型安全性的操作符。
		而malloc内存分配成功则是返回void * ，需要通过强制类型转换将void*指针转换成我们需要的类型。

		4.new会先调用operator new函数，申请足够的内存（通常底层使用malloc实现）。然后调用类型的构造函数，初始化成员变量，最后返回自定义类型指针。
		delete先调用析构函数，然后调用operator delete函数释放内存（通常底层使用free实现）。
        malloc/free是库函数，只能动态的申请和释放内存，无法强制要求其做自定义类型对象构造和析构工作。

		5.C++允许重载new/delete操作符，特别的，布局new的就不需要为对象分配内存，而是指定了一个地址作为内存起始区域，
		new在这段内存上为对象调用构造函数完成初始化工作，并返回此地址。而malloc不允许重载。

		malloc在堆上分配的内存块，使用free释放内存，而new所申请的内存则是在自由存储区上，使用delete来释放。
		堆是操作系统维护的一块内存，而自由存储区是C++中通过new与delete动态分配和释放对象的抽象概念。堆与自由存储区并不等价。

		- C++ 强制类型转换
		static_cast, dynamic_cast
		https://www.cnblogs.com/chenyangchun/p/6795923.html

 
- 数据结构
    - 堆  
    满足两个性质：其一：总是一棵完全二叉树；其二：某节点的值总是不大于或不小于其父节点的值。 
        - 大顶堆——根节点最大的堆叫做大顶堆  
        - 小顶堆——根节点最小的堆叫做小顶堆  
    - 栈
    后进先出  


    - B+树——数据库索引
    - B-树就是B树
	B树（B-tree）是一种树状数据结构，它能够存储数据、对其进行排序并允许以O(log n)的时间复杂度运行进行查找、顺序读取、插入和删除的数据结构。
	B树，概括来说是一个节点可以拥有多于2个子节点的二叉查找树。与自平衡二叉查找树不同，B-树为系统最优化大块数据的读和写操作。
	B-tree算法减少定位记录时所经历的中间过程，从而加快存取速度。普遍运用在数据库和文件系统。”
	B树的特点：
	根节点至少有两个子节点
    每个节点有M-1个key，并且以升序排列
    位于M-1和M key的子节点的值位于M-1 和M key对应的Value之间
    其它节点至少有M/2个子节点
	B+树是对B树的一种变形树，它与B树的差异在于：有k个子结点的结点必然有k个关键码；非叶结点仅具有索引作用，跟记录有关的信息均存放在叶结点中。
	                                            树的所有叶结点构成一个有序链表，可以按照关键码排序的次序遍历全部记录。（所以数据库中索引的实现就是B+树）
    B和B+树的区别在于，B+树的非叶子结点只包含导航信息，不包含实际的值，所有的叶子结点和相连的节点使用链表相连，便于区间查找和遍历

    - AVL树（平衡二叉树：它是一 棵空树或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树）

    - 红黑树——stl map/set（https://blog.csdn.net/sun_tttt/article/details/65445754）
	红黑树是一种自平衡二叉查找树，是在计算机科学中用到的一种数据结构，典型的用途是实现关联数组。
	红黑树是在普通二叉树上，对没个节点添加一个颜色属性形成的，同时整个红黑二叉树需要同时满足一下五条性质：
	性质一：节点是红色或者是黑色；
	性质二：根节点是黑色；
	性质三：每个叶节点（NIL或空节点）是黑色； 
	性质四：每个红色节点的两个子节点都是黑色的（也就是说不存在两个连续的红色节点）；
	性质五：从任一节点到其每个叶节点（NIL或空）的所有路径都包含相同数目的黑色节点；
	满足这五条性质的二叉树可以将查找删除维持在对数时间内。

    - 哈希表——数组+链表
	 哈希表（Hash table，也叫散列表），是根据关键码值(Key value)而直接进行访问的数据结构。查询为O（1）,一般情况下插入也是O（1）。
	 也就是说，它通过把关键码值映射到表中一个位置来访问记录，以加快查找的速度。这个映射函数叫做散列函数，存放记录的数组叫做散列表。
	 散列函数（哈希函数）的方法：
	 （1）直接取余法：关键字大小%散列表大小。h(key)=key%p。很多的书上认为，哈希表的大小最好是选择一个大的质数，并且最好不要和2的整数幂接近。最不好的选择是哈希表的大小恰好是2的整数幂。
	 （2）乘积取整法：关键字k乘以一个在(0,1)中的实数（最好是无理数），得到一个(0,1)之间的实数；取出其小数部分，乘以m，再取整数部分，即得K在Hash表中的位置。
	 哈希函数方法以及处理冲突的方法：http://www.360doc.com/content/14/0721/09/16319846_395862328.shtml
	 （开放定址法，再哈希法，链地址法）

	- 位串，位图（*）


- 算法
    - 排序
        - 冒泡（稳定）、选择（不稳定）、插入（稳定）  
            O(n^2)  
            选择排序：每一趟从待排序的数据元素中选择最小（或最大）的一个元素作为首元素，直到所有元素排完为止  
            插入排序：每一步将一个待排序的记录，插入到前面已经排好序的有序序列中去，直到插完所有元素为止。（从后往前比较）  
            冒泡排序：冒泡排序的基本思想是，对相邻的元素进行两两比较，顺序相反则进行交换，这样，每一趟会将最小或最大的元素“浮”到顶端，最终达到完全有序  
        - 快速排序——不稳定  
            每一趟取一个中枢元素，设置两个哨兵，一个左哨兵一个右哨兵，右哨兵往左遍历找到一个比中枢元素小的，左哨兵向右找到一个比中枢大的，交换这两个元素；重复上述行为，直至左右哨兵相遇，此时相遇的点即为中枢元素应该待的位置；而后以中枢元素为分解，左右两半重复上述过程。  
            因此，*每一趟排序下来都有一个中枢元素归位*。
            平均O(nlogn)，最差O(n^2)  
        - 归并排序——稳定
		    按照一定的增量去将排序数据分组，在组内利用直接插入排序
            最好最坏平均都为O(nlogn)
        - 堆排序——使用堆来进行排序，不稳定  
            将无序序列构造成堆，而后按照升序或降序选择大顶堆还是小顶堆，将堆构造成想要的堆，然后交换顶点元素与末尾元素（最后一个叶子节点）；而后针对剩下部分的子树继续调整成大顶堆or小顶堆重复上述过程；
            最好、最坏、平均都为O(nlogn)
        - 桶排序——类似于用位向量排序  
            适用于数据量大，且数据较为集中的数据集。如游戏中胜场数排名；  
            O(n)
        - 基数排序——不稳定
            分配的时间复杂度为O（n）  
            收集的的时间复杂度为O（radix）  
            分配和收集共需要distance趟  
            所以基数排序的时间复杂度为O(d(n+r))  
        - 空间复杂度：归并需要O（n），快排是O（logn），其它为O（1）（除桶和基数排序）
        - 超大规模数据的排序（多次归并、位向量、有关联数据的情况）

    - 图的广度优先——队列  
    - 图的深度优先——栈  

    - 最短路
        - 迪杰斯特拉  https://www.2cto.com/kf/201801/713595.html
    - 最小生成树
	    - Prim   https://blog.csdn.net/luoshixian099/article/details/51908175
    - 主要看剑指Offer
	- 贪心：贪心算法（又称贪婪算法）是指，在对问题求解时，总是做出在当前看来是最好的选择。也就是说，不从整体最优上加以考虑，他所做出的是在某种意义上的局部最优解。
            贪心算法不是对所有问题都能得到整体最优解，关键是贪心策略的选择，选择的贪心策略必须具备无后效性，即某个状态以前的过程不会影响以后的状态，只与当前状态有关。
	- 动态规划：研究多阶段决策过程(multistep decision process)的优化问题时，提出了著名的最优化原理(principle of optimality)，把多阶段过程转化为一系列单阶段问题，
	            利用各阶段之间的关系，逐个求解，创立了解决这类过程优化问题的新方法——动态规划。
	- 回溯：回溯算法实际上一个类似枚举的搜索尝试过程，主要是在搜索尝试过程中寻找问题的解，当发现已不满足求解条件时，就“回溯”返回，尝试别的路径。回溯法是一种选优搜索法，
	        按选优条件向前搜索，以达到目标。但当探索到某一步时，发现原先选择并不优或达不到目标，就退回一步重新选择，这种走不通就退回再走的技术为回溯法，
			而满足回溯条件的某个状态的点称为“回溯点”。


- 计算机网络
    - socket网络编程
	  具体见计算机网络的实验报告和 https://blog.csdn.net/a2011480169/article/details/73602708

    - 网络分层结构（七层就是应用层再分为应用层，表示层，会话层）
        - 应用层：HTTP、SMTP、DNS（域名解析协议）
        - 传输层：TCP（）、UDP、ICMP（互联网控制报文协议）
        - 网络层：IP、ARP协议（地址解析协议）
        - 数据链路层：MAC地址（media access control媒体访问控制，硬件唯一）
        - 物理层

    - TCP——可靠的、面向连接、全双工、点对点（三次握手，四次挥手中丢包怎么处理）
	   各步骤完成的状态：https://www.cnblogs.com/qingergege/p/6603488.html
        - 三次握手  
            客户端发送请求，SYN  
            服务端收到请求，发送SYN和ACK  
            客户端收到ACK，发送确认ACK  

            举个打电话的例子：  
            A : 你好我是A，你听得到我在说话吗（SYN）  
            B : 听到了（ACK），我是B，你听到我在说话吗（SYN）  
            A : 嗯，听到了（ACK）  

            之所以要三次，是因为客户端发送第一次SYN的时候可能服务端蛮久没收到，客户端等不及就再发送了一个SYN，此时服务端可能会收到两个SYN，
			因而认为客户端需要两个TCP连接，容易造成服务端资源浪费；因此客户端收到服务端的ACK后再发送一次ACK给服务端用于确认。
			（如果A向B发起TCP请求，B也按照正常情况进行响应了，但是A不进行第3次握手，这就是半连接。）
			
			为什么需要三次握手，两次不可以吗？或者四次、五次可以吗？ 
            我们来分析一种特殊情况，假设客户端请求建立连接，发给服务器SYN包等待服务器确认，服务器收到确认后，如果是两次握手，
			假设服务器给客户端在第二次握手时发送数据，数据从服务器发出，服务器认为连接已经建立，但在发送数据的过程中数据丢失，
			客户端认为连接没有建立，会进行重传。假设每次发送的数据一直在丢失，客户端一直SYN，服务器就会产生多个无效连接，
			占用资源，这个时候服务器可能会挂掉。这个现象就是我们听过的“SYN的洪水攻击”。 
            总结：第三次握手是为了防止：如果客户端迟迟没有收到服务器返回确认报文，这时会放弃连接，重新启动一条连接请求，
			但问题是：服务器不知道客户端没有收到，所以他会收到两个连接，浪费连接开销。如果每次都是这样，就会浪费多个连接开销。  

			第二次握手丢包？第三次握手丢包？
			第二次握手丢包可能会出现上述的SYN泛洪现象；第三次握手丢包，是第二次握手完成后服务器进入SYN_RECV状态，如果客户端发送给服务器的ACK丢包了，
			服务器没办法进入ESTABLISH状态，肯定不能传送数据。这时不管客户端是否主动发送数据与否，服务器都会定时重发第二次握手的SYN+ACK包，如果客户端再次发送ACK收到，
			则建立连接，否则超时之后，服务器给客户端发送RTS报文，进入CLOSED状态，防止SYN泛洪攻击。

        - 四次挥手  
            客户端发送FIN给服务端，请求断开连接  
            服务端收到FIN，发送ACK给客户端  
            服务端传送任务完成后断开与客户端的连接，并发送FIN给客户端  
            客户端收到FIN后发送ACK报文给服务端  

            举个例子：  
            A：你好，我没有东西要发给你了，我要的东西的清单也已经全发给你了（FIN），你发完了就断开连接吧。  
            B：知道了（ACK），我还没准备好，你再等我消息。   
            （一段时间后）   
            B：你好，你要的东西我都发完了（FIN），断开连接了啊。  
            A：知道了（ACK）。（再等一小段时间看有没有回复，没有则证明断开连接了）  
            之所以要四次握手，B需要确保自己发送给A的东西都发送完了，而A也需要保证B知道可以断开连接。

			客户端发送FIN后，进入终止等待状态，服务器收到客户端连接释放报文段后，就立即给客户端发送确认，服务器就进入CLOSE_WAIT状态，
			此时TCP服务器进程就通知高层应用进程，因而从客户端到服务器的连接就释放了。
			此时是“半关闭状态”，即客户端不可以发送给服务器，服务器可以发送给客户端。 （半打开是如果一方已经关闭或异常终止连接，而另一方却不知道。 我们将这样的TCP连接称为半打开（Half-Open））
            此时，如果服务器没有数据报发送给客户端，其应用程序就通知TCP释放连接，然后发送给客户端连接释放数据报，并等待确认。
			客户端发送确认后，进入TIME_WAIT状态，但是此时TCP连接还没有释放，然后经过等待计时器设置的2MSL后，才进入到CLOSE状态。
            为什么需要2MSL时间？ 
            首先，MSL即Maximum Segment Lifetime，就是最大报文生存时间，是任何报文在网络上的存在的最长时间，超过这个时间报文将被丢弃。
			《TCP/IP详解》中是这样描述的：MSL是任何报文段被丢弃前在网络内的最长时间。RFC 793中规定MSL为2分钟，实际应用中常用的是30秒、1分钟、2分钟等。

            TCP的TIME_WAIT需要等待2MSL，当TCP的一端发起主动关闭，三次挥手完成后发送第四次挥手的ACK包后就进入这个状态，
			等待2MSL时间主要目的是：防止最后一个ACK包对方没有收到，那么对方在超时后将重发第三次握手的FIN包，主动关闭端接到重发的FIN包后可以再发一个ACK应答包。
			在TIME_WAIT状态时两端的端口不能使用，要等到2MSL时间结束才可以继续使用。当连接处于2MSL等待阶段时任何迟到的报文段都将被丢弃。

	- Time_wait
	TCP的TIME_WAIT需要等待2MSL，当TCP的一端发起主动关闭，三次挥手完成后发送第四次挥手的ACK包后就进入这个状态
	TIME_WAIT：等待足够的时间过去以确保远端TCP 接收到它的连接终止请求的确认。
    TIME_WAIT 两个存在的理由：
          1.可靠的实现tcp全双工连接的终止；
          2.允许老的重复分节在网络中消逝。

	- TCP的拥塞控制
	https://www.cnblogs.com/losbyday/p/5847041.html
	TCP有滑动窗口

    - UDP——不可靠、无连接的  
        应用层可以更好地控制要发送的数据和发送的时间  
        无需建立连接，没有建立连接的延时  
        无需维护连接状态  
        分组首部开销小（TCP20字节首部，UDP8字节首部）
		  
    - HTTP  
        无状态协议——服务端不保存任何客户端的相关信息  
        使用TCP作为运输协议。  
        分为持久连接和非持久连接：  
            - 持久连接：完整的页面框架及其中包含的各对象都是用一个TCP连接来完成传送  
            - 非持久连接：网页框架的传送使用一个TCP连接，而后断开后依次建立连接传送其中包含的各个对象。  
        HTTP1.0和HTTP1.1的区别：其一、HTTP1.0需要keep-alive参数才可支持长连接，而HTTP1.1默认支持长连接；其二、HTTP1.1更节省带宽（支持发送只有头部的报文，用于测试是否有权限访问，无权限则后续直接可以不进行连接，从而节省带宽资源），同时支持断点续传（客户端已有资源不进行传送，只传送需要更新的部分）。  
        HTTP1.1和HTTP2.0的区别：其一、HTTP2.0支持多路复用，同一个连接并发处理多个请求；其二、HTTP2.0支持对头部信息进行压缩，HTTP1.1则不支持；其三、HTTP2.0支持服务器推送，即客户端发起web server请求时，服务端主动将一些客户端需要的资源发送给客户端，避免客户端再次创建连接获取资源。  

		http协议：超文本传输协议（HTTP，HyperText Transfer Protocol)是互联网上应用最为广泛的一种网络协议。所有的WWW文件都必须遵守这个标准。
		设计HTTP最初的目的是为了提供一种发布和接收HTML页面的方法。1960年美国人Ted Nelson构思了一种通过计算机处理文本信息的方法，并称之为超文本（hypertext）,这成为了HTTP超文本传输协议标准架构的发展根基。
		TCP长连接，短连接？https://baike.baidu.com/item/http/243074?fromtitle=HTTP%E5%8D%8F%E8%AE%AE&fromid=1276942&fr=aladdin#4 （6：工作原理）
		http缓存？https://www.cnblogs.com/chenqf/p/6386163.html
		http状态码：https://baike.baidu.com/item/HTTP%E7%8A%B6%E6%80%81%E7%A0%81/5053660
		1开头是消息类型，2开头是成功，3开头是重定向，4开头是请求错误，5开头是服务器错误

    - SYN洪泛攻击  
        TCP建立连接的三次握手过程中，服务器收到客户端发送的SYN后会将其加入到待处理队列中，这就导致SYN的到达必定会消耗服务端资源；因此，若到达的SYN过多，则容易导致服务器因内存消耗过大而耗尽资源。  
        解决办法：SYN缓存、SYN Cookies验证等（未涉猎）

    - 中间人攻击
        在正常的通信过程中，第三者欺骗客户端说自己是服务端，欺骗服务端说自己是客户端，从而实现劫持通信数据包。  
        实际上网络抓包的软件即基于此。  

    - DDOS
        通过大量的合法请求霸占服务器资源从而造成服务器瘫痪。  
        实际上SYN洪泛攻击、ACK洪泛攻击、ICMP洪泛攻击都属于此  

    - ARP攻击（地址解析协议）
    ARP攻击就是通过伪造IP地址和MAC地址实现ARP欺骗，能够在网络中产生大量的ARP通信量使网络阻塞，攻击者只要持续不断的发出伪造的ARP响应包就能更改目标主机ARP缓存中的IP-MAC条目，造成网络中断或中间人攻击。  
    ARP攻击常位于局域网中，局域网内有一台计算机感染该病毒即可。  

	- IO多路复用
	epoll和select
	https://www.cnblogs.com/simpman/p/4150005.html
	https://www.cnblogs.com/Anker/p/3265058.html


- 操作系统
    - 虚拟内存
	虚拟内存是计算机系统内存管理的一种技术。它使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间），
	而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。
	https://baike.baidu.com/item/%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98/101812#2
	深入理解计算机系统第9章

    - 32位与64位的区别  
        一次性处理数据不同——32位一次性处理32位的数据，64位则一次处理64位数据（64位系统加64位软件）；CPU的位数通常指内部寄存器的位数，32位CPU内部寄存器都只有32位长，64位CPU内部则为64位长的寄存器。  
        CPU地址总线根数不同（32位CPU有32根，64位CPU通常为40根）;  
        32位、64位下长度相同的类型：bool(1)、char(1)、short(2)、int(4)、float(4)、double(8)、longlong(8)  
        32位、64位下长度不同的类型：long-4-8、unsignedlong-4-8、指针类型-4-8  
    - 进程定义 
        进程包含文本区域、数据区域和堆栈；文本区域存储处理器执行的代码；数据区域存储变量和进程执行期间使用的动态分配的内存；堆栈区域存储着活动过程调用的指令和本地变量。  
        进程是一个实例化的程序。  
        进程的状态：  
            - 就绪：进程获取了除CPU以外的所有资源，随时可以准备运行；  
            - 运行：进程获得了CPU时间分配开始执行;  
            - 阻塞：进程等待其余资源就绪时，如等待I/O操作的时候；  
            - 阻塞态不可直接转为运行态，因为即使阻塞态等待的操作完成了，也还需要等待CPU分配，因此会进入就绪态；  
    - 进程的内存管理
        - 代码段：存放执行代码，只读，可能包含只读的常量  
        - 数据段：存放数据的内存，包括初始化为非零的数据区、BSS（一般存放未初始化的全局数据和静态数据）和堆（运行时动态分配的内存，程序员通过new/delete或malloc/free控制）；  
        - 堆栈段：即栈，用于存放程序临时创建的局部变量和函数参数，对程序员透明，不可控  
    - 给4MB空间，每次请求分配1K/2K或4K空间，怎么分配比较好
        - 注意内存对齐
        - 
    - 线程定义  
        通常在一个进程中可以包含若干个线程，一个进程中至少有一个线程。线程可以利用进程所拥有的资源，在操作系统中，进程作为分配资源的基本单位，线程作为独立运行和独立调度的基本单位；
		由于线程比进程更小，基本上不拥有系统资源，故对它的调度所付出的开销就会小得多，能更高效的提高系统多个程序间并发执行的程度。  
        线程拥有独立的堆栈空间，但是*共享数据段*，它们彼此之间使用相同的地址空间，共享大部分数据，比进程更节俭，开销比较小，切换速度也比进程快，效率高，但也因此不如进程安全。  
    - 死锁
        两个进程或线程因为互相等待对方完成特定操作而都进入阻塞态。  
        避免死锁的方式：  
            - 设置加锁顺序：为所有线程设置加锁的顺序，按照先后顺序排队加锁；因此需要事先知道所有可能会用到的锁，并知道锁的获取顺序。  
            - 线程请求加锁时会记录相应信息，因此当请求加锁时，可以检测是否存在对方向自己申请的加锁，从而避免死锁。  
            - 设置线程优先级（随机or其他）  

	- 进程间通信：管道、共享内存、消息队列、套接字、信号、信号量。（最快速的是共享内存）
	- fork()
	  fork()函数是C中创建子进程的函数。
	  fork()函数的实质是一个系统调用(和write函数类似),其作用是创建一个新的进程,当一个进程调用它,完成后就出现两个几乎一模一样的进程,
	  其中由fork()创建的新进程被称为子进程,而原来的进程称为父进程.子进程是父进程的一个拷贝,即子进程从父进程得到了数据段和堆栈的拷贝,
	  这些需要分配新的内存;而对于只读的代码段,通常使用共享内存方式进行访问.
	   
    - 互斥、同步  
        - 临界区（只可用于同一进程下的线程）:通过对多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问。  
            临界区实际上是一段代码，任意时刻都只有一个线程执行此段代码；当一个线程处于临界区中时，其余线程试图访问临界区代码时会被挂起，一直等到处于临界区的线程离开。
        - 互斥量（可用于线程也可以用于进程）:为协调共同对一个共享资源的单独访问而设计的。     
            只有拥有互斥对象的线程（进程）才可访问共享资源。
        - 信号量:为控制一个具有有限数量用户资源而设计。   
            信号量指出了同时访问共享资源的线程最大数目。它允许多个线程在同一时刻访问同一资源，但是需要限制在同一时刻访问此资源的最大线程数目。
			P操作（申请资源）信号量减1，若信号量仍大于等于0则继续执行，否则挂起进入调度程序；V操作（释放资源）信号量加1，若信号量大于0则继续执行，小于0则唤醒等待队列中的一个进程（线程）。  
        - 事件:用来通知线程有一些事件已发生，从而启动后继任务的开始。 
		- 同步：把异步环境下的一组并发进程因直接制约而互相发送消息而进行互相合作、互相等待，使得各进程按一定的速度执行的过程称为进程间的同步。

    - 字符串压缩（霍夫曼编码之类的方法）
        霍夫曼编码：出现频率高的编码短，频率低的编码长；且字符之间的编码互相不能为前缀。  
    - 错误校验（奇偶校验、CRC校验）  
        - 奇偶校验：实现约定好什么校验方式，检测二进制数据中1的个数是奇数还是偶数；  
        - CRC校验：https://baike.baidu.com/item/CRC%E6%A0%A1%E9%AA%8C/3439037#4


- 数据库
    - CAST和CONVERT的用法（用于类型转换，功能相同，cast一般更容易使用,convert的优点是可以格式化日期和数值.）
        - CAST('111' AS SIGNED)
        - CONVERT('111', SIGNED)
        - 只能对以下类型的数据使用：
            - 二进制，同带binary前缀的效果 : BINARY
            - 字符型，可带参数 : CHAR()
            - 日期 : DATE
            - 时间: TIME
            - 日期时间型 : DATETIME
            - 浮点数 : DECIMAL
            - 整数 : SIGNED
            - 无符号整数 : UNSIGNED

    - sql查询优化
        - 保证不查询多余的行与列  
            - 避免select *
            - 多使用where具体限定数据
            - 多使用top，查询字段少的情况下多使用distinct
        - 查询字段较多的情况下谨慎使用distinct
        - 慎用union关键字
        - 对大批量的操作进行分批处理

    - 内连接、左连接、右连接、完全连接、交叉连接
        - 内连接：内连接查询操作列出与连接条件匹配的数据行，它使用比较运算符比较被连接列的列值。
        - 左连接：是以左表为基准，将判断相等的数据进行连接，然后将左表没有的对应项显示，右表的列为NULL
        - 右连接：以右表为基准。
        - 完全连接：完整外部联接返回左表和右表中的所有行。当某行在另一个表中没有匹配行时，则另一个表的选择列表列包含空值。如果表之间有匹配行，则整个结果集行包含基表的数据值。
        - 交叉连接：笛卡尔积。交叉联接返回左表中的所有行，左表中的每一行与右表中的所有行组合。

    - 索引原理
        基于*B+树*的数据结构；
		优点，数据结构等  

    - 事务
        - 原子性：事务要么完全执行，要么全部失败回滚  
        - 一致性：事务的执行应当使数据库保持一致，即从一个一致的状态转到另一个一致的状态；  
        - 隔离性：当多个用户并发访问数据库时，比如操作同一张表时，数据库为每一个用户开启的事务，不能被其他事务的操作所干扰，多个并发事务之间要相互隔离，即对于任意两个并发的事务T1和T2，在事务T1看来，T2要么在T1开始之前就已经结束，要么在T1结束之后才开始，这样每个事务都感觉不到有其他事务在并发地执行。  
        - 持久性：持久性是指一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作。  
    - 日志
        - redo日志
            *事务commit位于数据持久化（写入到磁盘）之前，数据持久化之前一定要先确保日志写入到磁盘。*一旦系统中确认有事务的commit，则任务已经完成，且数据已写入数据库。因而当出现问题时，将所有commit的事务全部重新执行。
        - undo日志
            *没有commit的事务一律回滚到之前的状态，已经commit的日志则不处理。*因此，undo日志要确保事务commit之前先将数据持久化（写入到硬盘）。
    - SQL注入，如何防范
        当程序使用用户输入的内容来动态构造sql语句时，若未对用户输入的内容进行限制和筛选（对于存储过程也适用），则容易发生sql注入攻击。  
        如何防止sql注入：
            - 不相信用户的输入，主动对用户的输入进行限制、筛选；  
            - 不使用动态构造sql语句，尽量使用参数化的sql或使用ORM框架；  
            - 不适用管理员权限连接数据库，为每个应用或用户单独设置账号密码；  
	https://blog.csdn.net/qq_22222499/article/details/79060495
	https://www.2cto.com/database/201710/688377.html

- Linux
    - GDB常用命令：
	  gdb+调试程序名  启动
	  quit            退出
	  https://blog.csdn.net/yugemengjing/article/details/72661113

    - VIM

	http://gywbd.github.io/posts/2014/8/50-linux-commands.html （常用linux命令）
    - grep  
        查找、匹配特定字符串、正则表达式
    - sed  
        编辑、替换等  sed 's/原字符串/替换字符串/'
    - awk  
        提取前几行或给定d额域之类的操作 last -n 5 | awk  '{print $1}' 提取出前五行中的
    - find  
        在指定目录下查找符合指定表达式的文件or目录find /home -name "*.txt"
    - locate  
        查找目录or文件，但是查找的是mlocate.db的数据库文件，这个数据库每一天更新一次；故速度快，但有可能数据不一致，如被删除的文件也可以查找到，或者新建的文件查找不到等；可以通过updatedb命令更新数据库。  
    - whereis  
        whereis命令只能用于搜索程序名，而且只搜索二进制文件（参数-b）、man说明文件（参数-m）和源代码文件（参数-s）  
    - which  
        which命令是查找命令是否存在，以及命令的存放位置在哪儿。  
    - type  
        type命令用来区分某个命令到底是由shell自带的，还是由shell外部的独立二进制文件提供的。如果一个命令是外部命令，那么使用-p参数，会显示该命令的路径，相当于which命令。
		  
    - 内核态、用户态
	  从宏观上来看，Linux操作系统的体系架构分为用户态和内核态（或者用户空间和内核）。
	  内核从本质上看是一种软件——控制计算机的硬件资源，并提供上层应用程序运行的环境。
	  用户态即上层应用程序的活动空间，应用程序的执行必须依托于内核提供的资源，包括CPU资源、存储资源、I/O资源等。
	  为了使上层应用能够访问到这些资源，内核必须为上层应用提供访问的接口：即系统调用。

	- 文件系统（权限）
	  查看当前权限一般是ls -l。
	  权限管理命令是chmod 
	  chmod [{ugoa}{+-=}{rwx}] [文件或目录]  u:所有者, g:所属组,o:其他人,a:所有;
                     [mode=421] [文件或目录] +:添加权限,-减少权限,=直接赋值成这个权限
                     -R 递归修改
	 例如： chmod u+x 文件名（给文件的所有者添加执行权限）
	 https://jingyan.baidu.com/article/4853e1e5413b541909f72632.html

	- 硬链接和软链接
	硬链接类似于我新建一个inode把系统原有的一个inode的相关内容给复制过来，并且通过我新建的这个inode可以进行对内容的修改等操作
	软链接就类似于windows的快捷方式，只是提供一个访问方式，没别的什么作用。
	
	https://www.cnblogs.com/musen/p/8118396.html （常见面试题）

- 设计模式
    - 单例模式
        - 利用static成员对象和static成员函数
        - 构造函数为private，防止多次实例化
        - 判断是否存在，存在则返回，否则实例化；
            ```
            public class Singleton
            {
                private static Singleton Instance;

                private Singleton() { }

                public static Singleton GetInstance()
                {
                    if (Instance == null)
                    {
                        Instance = new Singleton();
                    }
                    return Instance;
                }
            }
            ```
    - 

- 题
    - 下楼梯，一个小人从屏幕顶下楼梯(类似于真男人下一百层，只不过楼梯不变)，只能在楼梯上左右移动，落在空中的时候不能动，掉落距离超过一定长度就摔死，空中掉落和左右移动都是1 m/s，问下到屏幕底所需的最短时间(第一想法，用dfs，bfs实现？)，动态规划  
        &emsp;&emsp;先从屏幕低到顶遍历一遍，确认好每个高度的楼梯对应的左边和右边楼梯，然而动态规划的方程dp[h] = min\[dp\[h->左\](左边的楼梯)+(左边楼梯移动的时间)+空中掉落的时间，dp\[h->右\](右边的楼梯)+(右边楼梯移动的时间)+空中掉落的时间）,边界条件就是底部dp[0]=0

    - 给定一个地图，分割为多块，怎么把建筑物的高度压缩到0-1.0的高度  
        &emsp;&emsp;实际上类似于数据处理中的标准化，去建筑物的最高最低值，然后得出建筑物的范围，再用每个建筑物的高度减去最小值后除以范围即可。

    - 射击游戏，怎么判断开枪后命中的目标(子弹可穿透)，目标如果有体积怎么检测  
        &emsp;&emsp;第一反应，类似图像处理中的直线段检测？实际上就是检测物体上是否存在多个点共着一条线，如果是这样的话就可以使用霍夫变换将直线空间转化为极坐标下的点集合？；另外是不是也可以从直线与面相交来入手。。。

    - 100层楼丢鸡蛋的问题：两个软硬程度一样但未知的鸡蛋，它们有可能都在一楼就摔碎，也可能从一百层楼摔下来没事。有座100层的建筑，要你用这两个鸡蛋确定哪一层是鸡蛋可以安全落下的最高位置。可以摔碎两个鸡蛋。
        &emsp;&emsp;假设我们要求最多k次测试完成，那么，第一次我们肯定只能在第k层进行测试，因为只有这样我们才能利用接下来的k-1次机会继续完成测试。如果第一次测试鸡蛋碎了，那么从低层开始一层一层利用第二个鸡蛋往上试探，最终在最多k-1次测试的时候可以找出想要的最高层数。如果第一次测试鸡蛋没有碎，则移动至k+k-1层处测试；若碎了，则从k层开始往上一层一层试探，若没碎，则向上移动k-2层（即移至k+k-1+k-2层）。以此类推；
        因此有
            k+(k-1)+(k-2)+……+1>=100
        解出k>=14，因此第一次测试最好从14层开始测试，因而最多需要14次测试即可完成。
